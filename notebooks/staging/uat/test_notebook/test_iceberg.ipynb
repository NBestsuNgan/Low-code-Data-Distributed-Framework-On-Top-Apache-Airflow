{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3275c7a-6c62-4993-bff6-ad78c341c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/22 09:12:05 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE DATABASE IF NOT EXISTS climate;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a75a58cd-ec6b-487d-a412-e0e08f13dca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS climate.weather (\n",
    "    datetime              timestamp,\n",
    "    temp                  double,\n",
    "    lat                   double,\n",
    "    long                  double,\n",
    "    cloud_coverage        string,\n",
    "    precip                double,\n",
    "    wind_speed            double\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (days(datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb2ce34e-8fd3-4efa-be19-a15abca9e1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>datetime</th>\n",
       "            <th>temp</th>\n",
       "            <th>lat</th>\n",
       "            <th>long</th>\n",
       "            <th>cloud_coverage</th>\n",
       "            <th>precip</th>\n",
       "            <th>wind_speed</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2023-08-16 00:00:00</td>\n",
       "            <td>76.2</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Partially sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>3.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-17 00:00:00</td>\n",
       "            <td>82.5</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Sunny</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-08-18 00:00:00</td>\n",
       "            <td>70.9</td>\n",
       "            <td>40.951908</td>\n",
       "            <td>-74.075272</td>\n",
       "            <td>Cloudy</td>\n",
       "            <td>0.5</td>\n",
       "            <td>5.2</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+------+-----------+------------+-----------------+--------+------------+\n",
       "|            datetime | temp |       lat |       long |  cloud_coverage | precip | wind_speed |\n",
       "+---------------------+------+-----------+------------+-----------------+--------+------------+\n",
       "| 2023-08-16 00:00:00 | 76.2 | 40.951908 | -74.075272 | Partially sunny |    0.0 |        3.5 |\n",
       "| 2023-08-17 00:00:00 | 82.5 | 40.951908 | -74.075272 |           Sunny |    0.0 |        1.2 |\n",
       "| 2023-08-18 00:00:00 | 70.9 | 40.951908 | -74.075272 |          Cloudy |    0.5 |        5.2 |\n",
       "+---------------------+------+-----------+------------+-----------------+--------+------------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from climate.weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a026bd9-4eb3-4a54-934c-1758f5759c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert data\n",
    "from datetime import datetime\n",
    "\n",
    "schema = spark.table(\"climate.weather\").schema\n",
    "\n",
    "data = [\n",
    "    (datetime(2023,8,16), 76.2, 40.951908, -74.075272, \"Partially sunny\", 0.0, 3.5),\n",
    "    (datetime(2023,8,17), 82.5, 40.951908, -74.075272, \"Sunny\", 0.0, 1.2),\n",
    "    (datetime(2023,8,18), 70.9, 40.951908, -74.075272, \"Cloudy\", .5, 5.2)\n",
    "  ]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.writeTo(\"climate.weather\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b50f932-bdc9-411e-b3b3-094d3390aea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/22 09:51:17 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---------+----------+---------------+------+----------+\n",
      "|           datetime|temp|      lat|      long| cloud_coverage|precip|wind_speed|\n",
      "+-------------------+----+---------+----------+---------------+------+----------+\n",
      "|2023-08-16 00:00:00|76.2|40.951908|-74.075272|Partially sunny|   0.0|       3.5|\n",
      "|2023-08-16 00:00:00|76.2|40.951908|-74.075272|Partially sunny|   0.0|       3.5|\n",
      "|2023-08-16 00:00:00|76.2|40.951908|-74.075272|Partially sunny|   0.0|       3.5|\n",
      "|2023-08-16 00:00:00|76.2|40.951908|-74.075272|Partially sunny|   0.0|       3.5|\n",
      "|2023-08-17 00:00:00|82.5|40.951908|-74.075272|          Sunny|   0.0|       1.2|\n",
      "|2023-08-17 00:00:00|82.5|40.951908|-74.075272|          Sunny|   0.0|       1.2|\n",
      "|2023-08-17 00:00:00|82.5|40.951908|-74.075272|          Sunny|   0.0|       1.2|\n",
      "|2023-08-17 00:00:00|82.5|40.951908|-74.075272|          Sunny|   0.0|       1.2|\n",
      "|2023-08-18 00:00:00|70.9|40.951908|-74.075272|         Cloudy|   0.5|       5.2|\n",
      "|2023-08-18 00:00:00|70.9|40.951908|-74.075272|         Cloudy|   0.5|       5.2|\n",
      "|2023-08-18 00:00:00|70.9|40.951908|-74.075272|         Cloudy|   0.5|       5.2|\n",
      "|2023-08-18 00:00:00|70.9|40.951908|-74.075272|         Cloudy|   0.5|       5.2|\n",
      "+-------------------+----+---------+----------+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://minio:9000',  # Replace with your MinIO server URL\n",
    "    config=Config(signature_version='s3v4')\n",
    ")\n",
    "\n",
    "# Initialize the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Parquet from S3\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Bucket name and folder prefix (path)\n",
    "bucket_name = 'warehouse'\n",
    "folder_prefix = 'climate/weather/data/'\n",
    "\n",
    "# List all the objects in the 'data' folder\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_prefix)\n",
    "\n",
    "# List to store Spark DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through all the objects and read each Parquet file\n",
    "for obj in response.get('Contents', []):\n",
    "    object_key = obj['Key']\n",
    "    \n",
    "    # Check if the object is a Parquet file (or if you want to apply other conditions)\n",
    "    if object_key.endswith('.parquet'):\n",
    "        # Get the Parquet file from MinIO\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "        parquet_data = response['Body'].read()\n",
    "        \n",
    "        # Read the Parquet data using PyArrow\n",
    "        table = pq.read_table(BytesIO(parquet_data))\n",
    "        \n",
    "        # Convert PyArrow Table to Spark DataFrame\n",
    "        df_spark = spark.createDataFrame(table.to_pandas())  # Convert pandas DataFrame to Spark DataFrame\n",
    "        \n",
    "        # Append the Spark DataFrame to the list\n",
    "        df_list.append(df_spark)\n",
    "\n",
    "# Combine all DataFrames into one Spark DataFrame if needed\n",
    "full_df_spark = df_list[0]\n",
    "for df in df_list[1:]:\n",
    "    full_df_spark = full_df_spark.union(df)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "full_df_spark.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
